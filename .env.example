# AI Provider Configuration
# Choose your AI provider: 'gemini' or 'huggingface'
AI_PROVIDER=gemini

# Google Gemini Configuration
GEMINI_API_KEY=your_gemini_api_key_here
# Optional: Specify a different Gemini model
# GEMINI_MODEL=gemini-2.5-flash

# Hugging Face Configuration
# Get your API key from https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=your_huggingface_api_key_here
# Optional: Specify a different model (defaults to Llama-3.2-11B-Vision-Instruct)
# HUGGINGFACE_MODEL=meta-llama/Llama-3.2-11B-Vision-Instruct
# Optional: Use a custom inference endpoint
# HUGGINGFACE_ENDPOINT=https://api-inference.huggingface.co/models/

# General AI Configuration (Optional)
# TEMPERATURE=0.7
# MAX_TOKENS=8192